# -*- coding: utf-8 -*-
"""logic_evaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x0h9YYqPLIjFZk8Nh3WZc690VaWa87y7
"""

from langchain.prompts import PromptTemplate
from langchain.output_parsers import PydanticOutputParser, OutputFixingParser
from pydantic import BaseModel, Field
from langchain_core.language_models.chat_models import BaseChatModel
from langchain_core.documents import Document
from typing import List

# Import the StructuredQuery class from your parser file
from llm_parser_savi import StructuredQuery

# The FinalAnswer Pydantic model remains the same
class FinalAnswer(BaseModel):
    """A structured format for the final comprehensive answer."""
    answer: str = Field(description="A direct, standalone answer to the user's question, phrased as a complete sentence based on the provided source clause.")


class AnswerGenerator:
    """
    Generates a final, structured answer based on the query and retrieved documents.
    """
    def __init__(self, llm: BaseChatModel):
        self.llm = llm
        self.parser = PydanticOutputParser(pydantic_object=FinalAnswer)

        # 2. Create the OutputFixingParser, wrapping your original parser
        self.output_fixing_parser = OutputFixingParser.from_llm(
            parser=self.parser, llm=self.llm
        )

        # The new PromptTemplate inside AnswerGenerator.__init__
        self.prompt = PromptTemplate(
            input_variables=["raw_query", "query_type","context"],
            partial_variables={"format_instructions": self.parser.get_format_instructions()},
            template="""
            
You are an Precise Research Assistant. Your expertise is in carefully analyzing any provided text—be it a technical policy or a historical document—and extracting clear and accurate answers. Base your response strictly on the provided source clauses.
You are working with a limited context. You have ONLY:
• The Source Clauses (the top 10 most relevant text snippets from a larger document).
• The user’s original question (raw_query).
• The question type (query_type).
You MUST NOT hallucinate or add any facts beyond what is present in the provided Source Clauses.

=== OVERALL GOAL ===
Produce a concise, correct answer in JSON. Your primary challenge is to determine if the 10 chunks you've received are sufficient to answer the question and to synthesize information from multiple chunks whenever necessary.

=== UNDERSTANDING THE CONTEXT FORMAT ===
The `Source Clauses` you receive are formatted in Markdown. Understanding this structure is critical for accurate answers.

    **1. Headings and Emphasis: 
    *Any text formatted with markdown for headings (e.g., #, ##) or emphasis (e.g., **bold**) is provided at the very start of the chunk 

    **2. Tables:
    *You can identify a table by the repeated use of the pipe | separator.
    *Each line represents a single row.

    **3. General Text: 
    *All other text is standard prose. Pay close attention to lists, definitions, and clauses that specify conditions or **EXCLUSIONS**.

=== Step 0: Triage for Query Intent ===
Before you begin the workflow, you MUST first triage the user's `raw_query` to determine its intent. Your goal is to distinguish between a user asking **ABOUT** a rule versus a user asking for **ACCESS** to **FORBIDDEN** information or **INSTRUCTIONS** on how to break a rule.

    **Case 1: Legitimate Queries:**
    * You MUST proceed with the main workflow for queries asking about rules, definitions, consequences, or possibilities, even if the topic sounds sensitive (e.g., fraud, forged documents, cosmetic surgery). The user is asking "What is the rule?", which you should answer from the policy.

    **Case 2: Inappropriate Queries:**
    * You must refuse a query ONLY IF it asks for one of the following. If it does, stop immediately and return the refusal sentence.
    * 1. Access to Confidential Information: The query asks for information that is clearly private, proprietary, or non-public and would not be in a public document (e.g., "give me the claim settlement algorithm," "list all customers," "show me internal chat logs"). This does NOT include requests for public resources like a list of network hospitals.
    * 2. Instructions for Illegal Acts: The query asks for guidance on how to commit fraud, forge documents, or perform any illegal activity (e.g., "how to fake a medical report," "how to commit insurance fraud"). This does NOT include legitimate questions about policy rules or conditions.
    * 3. Personal Data about Other Policyholders: The query asks for personal information about other policyholders (e.g., "who are the other policyholders in this plan?"). This is not allowed under any circumstances.
    * **Refusal sentence** : "I cannot answer this question as it requests access to confidential/proprietary data or asks for instructions on actions that are against policy rules."
 
=== DETAILED WORKFLOW ===

**Important: Write the answer in your own words and in a responsive manner, making sure to include all the relevant information and write the most relevant part first.**

1.  **Context Assessment & Synthesis (Primary Method):**
    a. First, scan ALL 10 provided Source Clauses. Your initial goal is to see if the query requires connecting information from multiple chunks (e.g., a benefit from chunk 1, a condition from chunk 4, and an exclusion from chunk 7).
    b. If a complete answer requires combining information, synthesize the findings from all relevant chunks into a single, coherent paragraph. This is the preferred method for complex questions.

2.  **Simple Extraction (Fallback Method):**
    a. If, and only if, the query is simple (like a single definition) and one Source Clause provides the complete and direct answer, you may use that single clause. This is a fallback for straightforward questions.

3.  **Answer Construction & Formatting:**
    a. Rewrite the synthesized findings (or the single-clause answer) clearly and concisely.
    b. **Crucially, you must preserve ALL critical details**: numeric values, time periods (e.g., '48 hours'), percentages, and specific conditions (e.g., 'only for Platinum plan') EXACTLY as they appear in the source. Clarity and accuracy are more important than a strict word count.
    c. For **yes_no** questions, begin with “Yes,” or “No,”.
    d. For **definition** questions, start with “[Term] is …”.
    e. For **numeric_factoid**, begin with the number or unit.
    f. For **listing**, use bullet-style semantics (“They are: …”).
    g. Then remove the less relevant part from the standalone answer.

4.  **Determine Answer Completeness and Construct the Final Response:**
    After analyzing all 10 chunks, you must determine the completeness of the information you have. Then, construct your final answer according to one of the three levels below.
    
    **Level 1: If you have COMPLETE information to answer the query:**
    * Construct the full, comprehensive answer based on your synthesis of the clauses, following the formatting rules in Step 3.

    **Level 2: If you have PARTIAL information (A partial answer is better than no answer):**
    * First, state the information that you *were* able to find in the provided clauses.
    * Then, add a concluding sentence that explicitly states what critical information is missing from the context you were given.
    * **Example of a final partial answer:** "The policy covers robotic surgery up to a sub-limit of ₹2,00,000. However, the provided clauses do not specify if 'Apollo Care Hospital' is a network provider."

    **Level 3: If you have NO RELEVANT information:**
    * Only in the case where **none** of the 10 provided chunks contain information relevant to the user's question, you must return the following sentence exactly:
    * "I'm sorry, but none of the provided policy clauses contain information relevant to your question."

**Format Instructions:**
{format_instructions}

---
**CONTEXT (Source Clauses):**
{context}

---
**QUESTION:**
{raw_query}

**QUESTION TYPE**
{query_type}
"""
)
        
#         self.prompt = PromptTemplate(
#             template="""You are an expert insurance policy analyst. Your task is to provide a clear and concise answer based ONLY on the provided context (Source Clauses).

# Follow these steps carefully:
# 1.  Review the User's Subject and Specific Questions to understand what they are asking.
# 2.  Analyze the Source Clauses to find relevant information.
# 3.  If the Source Clauses do not contain the information, state that the answer cannot be found in the document.
# 4.  If the information is present, formulate a direct answer.
# 5.  Write a detailed explanation for your answer and list the exact source clauses used.

# Format your entire output as a JSON object according to these instructions:
# {format_instructions}

# ---
# CONTEXT (Source Clauses):
# {context}

# ---
# USER'S MAIN SUBJECT:
# {subject}

# USER'S SPECIFIC QUESTIONS:
# {question}
# """,
#             # Add "subject" to the input variables
#             input_variables=["question", "context", "subject"],
#             partial_variables={"format_instructions": self.parser.get_format_instructions()},
#         )
        
        self.generation_chain = self.prompt | self.llm | self.output_fixing_parser

    async def generate_answer(self, structured_query: StructuredQuery, final_documents: List[Document]) -> FinalAnswer:
        """
        Takes the query and final documents and returns a structured answer.
        """
        print("\nGenerating final answer based on re-ranked documents...")
        
        context_str = "\n---\n".join([doc.page_content for doc in final_documents])
        
        # Update the invoke call to include the new "subject" variable
        return await self.generation_chain.ainvoke({
            "context": context_str,
            "raw_query": structured_query.raw_query,
            "query_type": structured_query.query_type.value
        })



# You are an expert insurance policy analyst. You have ONLY:
#   • The Source Clauses (raw text snippets).  
#   • The user’s original question (raw_query).  
#   • The question type (query_type).  
# You MUST NOT hallucinate or add any facts beyond these clauses.

# === OVERALL GOAL ===  
# Produce a concise, correct answer in JSON, following the format instructions exactly.

# === DETAILED WORKFLOW ===  

#  **Important : Write the answer in your own words and in a responsive manner, make sure to include all the relevant information and write the most relevant part first**

# 1. **Identify Relevance**  
#    a. Read raw_query carefully—note keywords and conditions (e.g. “knee surgery,” “waiting period,” numeric values).  
#    b. Scan each Source Clause for direct matches or paraphrases of those keywords.  

# 2. **Select & Quote**  
#    a. Pick the single clause sentence that best answers the question.  
#    b. Copy it **verbatim** (including any numbers or percentages).  
#    c. If no single clause suffices, select the two most relevant sentences.  

# 3. **Paraphrase**  
#    a. Rewrite each quoted sentence in your own words, using **no more than 25 words** per paraphrase.  
#    b. Preserve **all** numeric values, time periods, conditions, and percentages exactly.  

# 4. **Assemble Final Answer**  
#    a. If you used one clause: output its paraphrase.  
#    b. If you used two clauses: output the first paraphrase, then prefix the second with “Additionally, …”.  
#    c. For **yes_no** questions, begin with “Yes,” or “No,” as appropriate, then add your paraphrase.  
#    d. For **definition** questions, start with “[Term] is …”  
#    e. For **numeric_factoid**, begin with the number or unit (“Thirty-six months …”).  
#    f. For **listing**, use bullet-style semantics (“They are: …”).  
#    g. Then remove the less relevant part from the standalone answer


# 5. **Insufficient Info**  
#    If no clause can answer, return exactly:  
#    "insufficient_information"